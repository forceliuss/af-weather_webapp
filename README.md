# Weather Data Pipeline - ETL com Airflow, Supabase e Streamlit

Este projeto demonstra a construÃ§Ã£o de um pipeline ETL completo para ingestÃ£o e transformaÃ§Ã£o de dados meteorolÃ³gicos, utilizando Apache Airflow, Supabase e Streamlit para visualizaÃ§Ã£o.

## ğŸ“º VÃ­deo do Projeto

Este repositÃ³rio estÃ¡ vinculado ao seguinte vÃ­deo do YouTube:

**TÃ­tulo:** Construindo um pipeline de ingestÃ£o e transformaÃ§Ã£o de dados | Airflow + Supabase + Streamlit  
**Link:** https://youtu.be/L7CGbQmPElQ

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um pipeline de dados end-to-end que:

1. **Extrai** dados meteorolÃ³gicos da API do OpenWeatherMap para a cidade do Rio de Janeiro
2. **Transforma** os dados (normalizaÃ§Ã£o, conversÃ£o de unidades, enriquecimento)
3. **Carrega** os dados transformados no Supabase (PostgreSQL)
4. **Visualiza** os dados atravÃ©s de um dashboard interativo em Streamlit

## ğŸ—ï¸ Arquitetura

- **Apache Airflow**: OrquestraÃ§Ã£o do pipeline ETL
- **Astronomer**: Ambiente de desenvolvimento e execuÃ§Ã£o do Airflow
- **OpenWeatherMap API**: Fonte de dados meteorolÃ³gicos
- **Supabase**: Banco de dados PostgreSQL na nuvem
- **Streamlit**: Dashboard web para visualizaÃ§Ã£o dos dados

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ weather_pipeline.py    # DAG do Airflow com as tarefas ETL
â”œâ”€â”€ app.py                      # AplicaÃ§Ã£o Streamlit para visualizaÃ§Ã£o
â”œâ”€â”€ requirements.txt            # DependÃªncias Python do projeto
â”œâ”€â”€ Dockerfile                  # Imagem Docker do Astro Runtime
â”œâ”€â”€ airflow_settings.yaml      # ConfiguraÃ§Ãµes locais do Airflow
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ”§ PrÃ©-requisitos

- Python 3.8+
- Docker e Docker Compose
- Astronomer CLI instalado
- Conta no OpenWeatherMap (API Key gratuita)
- Projeto no Supabase configurado

## ğŸš€ ConfiguraÃ§Ã£o

### 1. Instalar Astronomer CLI

Siga as instruÃ§Ãµes em: https://www.astronomer.io/docs/astro/cli/install-cli

### 2. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```bash
# OpenWeatherMap API
OPENWEATHER_API_KEY=sua_api_key_aqui

# Supabase Database
DB_HOST=seu_host_supabase
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_PORT=5432
DB_DBNAME=postgres
```

### 3. Iniciar o Ambiente Airflow

```bash
astro dev start
```

Este comando irÃ¡ iniciar 4 containers Docker:

- **Postgres**: Banco de dados de metadados do Airflow
- **Webserver**: Interface web do Airflow (porta 8080)
- **Scheduler**: Componente que monitora e dispara as tarefas
- **Triggerer**: Componente responsÃ¡vel por tarefas deferidas

### 4. Acessar o Airflow UI

Acesse http://localhost:8080/ e faÃ§a login com:

- **Username:** `admin`
- **Password:** `admin`

### 5. Executar o Streamlit App

Em um terminal separado:

```bash
streamlit run app.py
```

O dashboard estarÃ¡ disponÃ­vel em http://localhost:8501

## ğŸ“Š Pipeline ETL

O DAG `weather_pipeline` executa as seguintes tarefas:

1. **Extract**: Busca dados meteorolÃ³gicos da API OpenWeatherMap
2. **Transform**:
   - Normaliza dados aninhados (weather, sys, etc.)
   - Converte temperaturas de Kelvin para Celsius
   - Adiciona timestamp de coleta
   - Estrutura dados para o schema do banco
3. **Load**: Insere dados transformados no Supabase

O pipeline Ã© executado a cada 2 minutos por padrÃ£o.

## ğŸ—„ï¸ Schema do Banco de Dados

Os dados sÃ£o armazenados na tabela `weather.weather_data` com os seguintes campos principais:

- InformaÃ§Ãµes bÃ¡sicas: `city`, `collection_timestamp`
- Temperaturas: `temperature_c`, `thermal_sensation_c`, `temp_min_c`, `temp_max_c`
- CondiÃ§Ãµes: `humidity`, `pressure`, `wind_speed`, `wind_direction`
- LocalizaÃ§Ã£o: `latitude`, `longitude`
- Clima: `weather_main`, `weather_description`, `weather_icon`
- Sistema: `sys_country`, `sys_sunrise`, `sys_sunset`

## ğŸ“š Recursos e DocumentaÃ§Ã£o

### Tutoriais e Guias

- [PT] InstalaÃ§Ã£o Python - https://www.youtube.com/watch?v=-M4pMd2yQOM
- [EN] Ambiente Conda - https://www.youtube.com/watch?v=qI3P7zMMsgY
- [EN] ConfiguraÃ§Ã£o Supabase - https://www.youtube.com/watch?v=zBZgdTb-dns
- [EN] ComeÃ§ando com Astronomer - https://www.youtube.com/watch?v=Gvw1QZ4oUiw

### DocumentaÃ§Ã£o Oficial

- [Anaconda Guide](https://www.anaconda.com/docs/getting-started/anaconda/install)
- [Astronomer Documentation](https://www.astronomer.io/docs/home/astronomer-documentation)
- [OpenWeatherMap API](https://openweathermap.org/current)
- [Streamlit Documentation](https://docs.streamlit.io/)

## ğŸ› ï¸ Tecnologias Utilizadas

- **Apache Airflow**: OrquestraÃ§Ã£o de workflows
- **Astronomer**: Runtime e ferramentas para Airflow
- **Python**: Linguagem de programaÃ§Ã£o
- **Pandas**: ManipulaÃ§Ã£o de dados
- **SQLAlchemy**: ORM e conexÃ£o com banco de dados
- **Streamlit**: Framework para aplicaÃ§Ãµes web
- **Plotly**: VisualizaÃ§Ãµes interativas
- **Supabase**: Banco de dados PostgreSQL gerenciado

## ğŸ“ Notas

- O pipeline coleta dados para a cidade do Rio de Janeiro por padrÃ£o
- Os dados sÃ£o armazenados em um schema separado (`weather`) no Supabase
- O dashboard Streamlit atualiza automaticamente a cada 2 minutos
- Certifique-se de ter uma API Key vÃ¡lida do OpenWeatherMap

## ğŸ¤ Contribuindo

Este Ã© um projeto educacional vinculado a um vÃ­deo do YouTube. Sinta-se Ã  vontade para fazer fork e adaptar para suas necessidades!

## ğŸ“§ Contato

Para conteÃºdo mais aprofundado sobre o mundo de dados:

- **Substack**: https://substack.com/@forcelius
- **Medium**: https://medium.com/@forceliuss

---

**Soundtracks:** Epidemic Sound - https://share.epidemicsound.com/82aru1
